{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae7600e",
   "metadata": {},
   "source": [
    "# Stopword Removal (Remoção de palavras irrelevantes)\n",
    "\n",
    "## Conteúdo\n",
    "\n",
    " - 01 - Introdução a Stopword (Palavras irrelevantes)\n",
    " - 02 - Removendo Stopword com a biblioteca NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1faceb5",
   "metadata": {},
   "source": [
    "## 01 - Introdução a Stopword (Palavras irrelevantes)\n",
    "\n",
    "> No processamento de linguagem natural, a remoção de palavras irrelevantes é o processo de remover palavras de uma string que não fornecem nenhuma informação sobre o tom de uma declaração.\n",
    "\n",
    "**Palavras irrelevantes (Stopword)** são palavras que removemos durante o pré-processamento, quando não nos importamos com a estrutura das frases. Geralmente são as palavras mais comuns em um idioma e não fornecem nenhuma informação sobre o tom de uma declaração.\n",
    "\n",
    "Eles incluem palavras como:\n",
    "\n",
    " - **“a”**\n",
    " - **“an”**\n",
    " - **“the”**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e34f65",
   "metadata": {},
   "source": [
    "## 02 - Removendo Stopword com a biblioteca NLTK\n",
    "\n",
    "> A biblioteca **NLTK** fornece uma biblioteca integrada com essas palavras.\n",
    "\n",
    "Veja o código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f179cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NBC', 'founded', '1926', 'making', 'oldest', 'major', 'broadcast', 'network', 'USA']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Sentence to apply Stopword removal.\n",
    "nbc_statement = \"NBC was founded in 1926 making it the oldest major broadcast network in the USA\"\n",
    "\n",
    "word_tokens = word_tokenize(nbc_statement) # Tokenize nbc_statement\n",
    "statement_no_stop = [word for word in word_tokens if word not in stop_words] # Apply list comprehension\n",
    "\n",
    "print(statement_no_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49963bdf",
   "metadata": {},
   "source": [
    "Veja que para remover as **palavras irrelevantes (Stopword)** foi feito vários processos antes disso, que foram:\n",
    "\n",
    " - **Baixar as Stopword**\n",
    " - **Transformar as Stopword em um conjunto (set)**\n",
    "   - Veja que nós estamos utilizando as Stopword da língua Inglesa (English).\n",
    " - **Separar/Tokenzinar o texto por palavras:**\n",
    "   - Veja que nós não estamos considerando ponto e vírgula *(que também não tem no texto)*.\n",
    "   - E também não estamos separando por sentenças e sim por palavras.\n",
    " - **Aplicar uma *list comprehension* que retorna apenas as palavras que não estão no conjunto de Stopword.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca474bd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**REFERÊNCIAS:**  \n",
    "[CodeAcademy - Text Preprocessing](https://www.codecademy.com/learn/text-preprocessing)\n",
    "\n",
    "---\n",
    "\n",
    "**Rodrigo Leite -** *drigols*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
