# Pythonando (Arcane 06 - 2025)

 - **Teoria:**
   - [RAG (Retrieval-Augmented Generation)](#intro-to-rag)
   - [Chunks](#intro-to-chunks)
   - [Overlap](#intro-to-overlap)
   - [RAG + Retriever (Implementa√ß√£o)](#rag-retriever)
 - **Implementa√ß√£o:**
   - [Criando o projeto "core" do djando](#django-core)
   - [Criando e configurando o app "users"](#app-users)
   - [Mapeando a rota "users" com a view "register"](#mapping-users-to-register-view)
<!---
[WHITESPACE RULES]
- Same topic = "20" Whitespace character.
--->






































































































<!--- ( Teoria ) --->

---

<div id="intro-to-rag"></div>

## RAG (Retrieval-Augmented Generation)

Retrieval‚ÄëAugmented Generation (RAG) √© uma t√©cnica que combina:

 - Recupera√ß√£o de documentos (retrieval);
 - Com modelos geradores de linguagem (generation).

Em vez de confiar apenas no conhecimento ‚Äúembutido‚Äù nos par√¢metros do modelo, o RAG permite que o sistema v√° buscar trechos de texto relevantes em uma base externa (por exemplo, Wikipedia, banco de documentos corporativos) e use essas informa√ß√µes para gerar respostas mais precisas e contextualizadas.

![img](images/rag-01.png)  

### Quando utilizar RAG

 - **Base de conhecimento grande e em constante atualiza√ß√£o:**
   - Documenta√ß√µes, FAQs, bases cient√≠ficas.
 - **Dom√≠nios t√©cnicos/especializados:**
   - Jur√≠dico, m√©dico, pesquisadores que exigem precis√£o e cita√ß√µes.
 - **Sistemas de suporte ao cliente:**
   - Chatbots que precisam referenciar manuais, pol√≠ticas, termos de servi√ßo.

### Quando n√£o utilizar RAG

 - **Tarefas de conversa√ß√£o livre:**
   - Bate‚Äëpapo informal, cria√ß√£o de conte√∫do criativo onde n√£o h√° necessidade de buscar fatos externos.
 - **Restri√ß√µes de lat√™ncia:**
   - Se seu sistema exige respostas em tempo real (<100‚ÄØms) e n√£o comporta o tempo extra de recupera√ß√£o.
 - **Ambientes com poucos dados:**
   - Se a base de documentos for pequena e autossuficiente, pode ser mais simples usar um LLM puro ou at√© finetuning.




















---

<div id="intro-to-chunks"></div>

## Chunks

> Imagina que voc√™ precisa criar um *RAG* que utiliza a **Constitui√ß√£o Federal** para auxiliar advogados.

Se, para uma pergunta sobre **direito do consumidor**, enviarmos *toda a constitui√ß√£o*, isso far√° com que o modelo de IA n√£o consiga processar todas as informa√ß√µes, j√° que, quanto maior o prompt, **menos precisa tende a ser a resposta**.

Para isso, utilizamos a t√©cnica de **"chunks"**, onde, pegamos um arquivo geral e o quebramos em v√°rios pequenos trechos:

![img](images/chunks-01.png)  

> **NOTE:**  
> Podemos usar um `chunk_size` para especificar quantos caracteres teremos por **chunk**.

A *Constitui√ß√£o Federal* possui **64.488 palavras**. Se definirmos um `chunk_size` como **100**, teremos **645 mini arquivos (64.488√∑100)** da Constitui√ß√£o.

### üßæ Exemplos:

 - **Art. 1¬∫** A Rep√∫blica Federativa do Brasil, formada pela uni√£o indissol√∫vel dos Estados e Munic√≠pios e do Distrito Federal, constitui-se em Estado Democr√°tico de Direito e tem como fundamentos...
 - **Par√°grafo √∫nico.** Todo o poder emana do povo, que o exerce por meio de representantes eleitos ou diretamente, nos termos desta Constitui√ß√£o...
 - **Art. 2¬∫** S√£o Poderes da Uni√£o, independentes e harm√¥nicos entre si, o Legislativo, o Executivo e o Judici√°rio...




















---

<div id="intro-to-overlap"></div>

## Overlap

**Mas agora enfrentamos outro problema:**  
Ao separar o texto por chunks, pode ser que eles **fiquem sem sentido**, j√° que partes importantes da informa√ß√£o podem ser **cortadas (separadas)**.

> **NOTE:**  
> Para isso, usamos o par√¢metro `chunk_overlap`.

 - Ele define quantos caracteres de sobreposi√ß√£o haver√° entre um chunk e o pr√≥ximo.
 - üëâ Isso √© √∫til para manter o contexto entre peda√ßos consecutivos.

Por exemplo, Exemplo com `chunk_size = 500` e `chunk_overlap = 100`

```bash
[000 ... 499]
[400 ... 899]
[800 ... 1299]
```

Vejam que:

 - **Nosso primeiro chunk comeca em 000 e termina em 499:**
   - Ou seja, as primeiras 500 palavras da Constitui√ß√£o.
 - **Nosso segundo chunk come√ßa em 400 (por causa do "chunk_overlap = 100") e termina em 899:**
   - Ou seja, ele est√° pegando as 100 √∫ltimas palavras do chunk anterior.
   - **NOTE:** Isso √© importante para evitar perda de contexto entre os chunks.

Por exemplo, imagine que temos o seguinte texto:

```bash
Python √© uma excelente linguagem de programa√ß√£o para web e IA.
```

Se aplicarmos:

 - `chunk_size = 7`
 - `chunk_overlap = 3`

Vamos ter:

```bash
Python √© uma excelente linguagem de programa√ß√£o para web e IA.
   |   |  |      |         |     |       |
   0   1  2      3         4     5       6
   ---------------------------------------
                chunk 1


Python √© uma excelente linguagem de programa√ß√£o para web e IA.
                           |     |       |       |    |  |  |
                           1     2       3       4    5  6  7
                           -----------------------------------
                                        chunk 2
```

> **NOTE:**  
> Vejam que n√≥s pegamos as **3 √∫ltimas palavras do chunk (overlap = 3)** para n√£o perde contexto.




















---

<div id="rag-retriever"></div>

## RAG + Retriever (Implementa√ß√£o)

> Aqui vamos aprender o b√°sico de como implementar um `RAG (Retrieval-Augmented Generation)` baseado em `Retriever`.

De in√≠cio vamos ler um documento (PDF) e para isso a biblioteca LangChain j√° tem uma fun√ß√£o pronta para isso:

[rag_retriever.py](rag_retriever.py)
```python
pdf_pah = "perceptron.pdf"     # PDF path
loader = PyPDFLoader(pdf_pah)  # PDF loader
pdf = loader.load()            # PDF documents

print("Document type:", type(pdf))
print("Document content:", pdf)
```

> **NOTE:**  
> O c√≥digo acima vai printar v√°rias informa√ß√µes sobre o documento (PDF) que foi lido, como, conte√∫do, n√∫mero de p√°ginas e etc.

Continuando, agora n√≥s vamos quebrar o conte√∫do do documento em v√°rias `chunks` e `overlap`:

[rag_retriever.py](rag_retriever.py)
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Cria um splitter de 500 (documentos) e overlap de 100 (100 palavras casa)
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)

# Divide (splita) o PDF em chunks
chunks = splitter.split_documents(pdf)

for index, chunk in enumerate(chunks):
    if index == 5:
        break
    print(chunk.page_content, "\n\n")
```

**OUTPUT:**
```bash
Perceptron
tags: #python_full_ai  #perceptron
Perceptron: Fundamentos Te√≥ricos e
matem√°ticos
O Perceptron constitui a base fundamental para o desenvolvimento
de redes neurais mais complexas. Este material explora sua teoria,
formula√ß√£o matem√°tica e aplica√ß√µes pr√°ticas.
Fundamentos Hist√≥ricos e Conceituais
Em 1943, Warren McCulloch e Walter Pitts publicaram o artigo que
revolucionou todo o nosso entendimento moderno sobre intelig√™ncias 


revolucionou todo o nosso entendimento moderno sobre intelig√™ncias
artificiais como as conhecemos hoje, desde o ChatGPT, MidJourney,
ClaudeAI, entre outros.
"A Logical Calculus of the Ideas Immanent in Nervous Activity"
nos deu a ideia do primeiro neur√¥nio artificial, baseado nos neur√¥nios
biol√≥gicos do nosso pr√≥prio c√©rebro, chamado de Perceptron.
O Perceptron √© um classificador bin√°rio de problemas linearmente
separ√°veis. Ele √© a forma mais elementar de uma rede neural e, por 


separ√°veis. Ele √© a forma mais elementar de uma rede neural e, por
isso, individualmente, n√£o √© capaz de resolver muitos problemas, j√°
que seria equiparado a um √∫nico neur√¥nio do nosso c√©rebro.
Contudo, ele nos permite a cria√ß√£o do Multilayer Perceptron, um
conjunto de Perceptrons ligados em camadas, que d√° origem √†s
redes neurais.
Funcionamento do Perceptron 


Onde:
A imagem acima serve apenas como uma representa√ß√£o humanizada
do Perceptron para fins did√°ticos. No entanto, para o computador, o
Perceptron nada mais √© do que uma fun√ß√£o matem√°tica.
O problema de representar o Perceptron dessa maneira √© que a
fun√ß√£o resultante s√≥ funciona com dois valores de entrada. Para que
ele seja mais √∫til e escal√°vel, precisamos express√°-lo de forma
din√¢mica, capaz de lidar com m√∫ltiplas entradas.
Z=
N
‚àë
i=1
xiwi
x‚ÇÅ, x‚ÇÇ, ..., x ‚Çô  s√£o as entradas 


din√¢mica, capaz de lidar com m√∫ltiplas entradas.
Z=
N
‚àë
i=1
xiwi
x‚ÇÅ, x‚ÇÇ, ..., x ‚Çô  s√£o as entradas
w‚ÇÅ, w‚ÇÇ, ..., w ‚Çô  s√£o os pesos que representam o aprendizado do
modelo
Œ£ representa a soma ponderada das entradas pelos pesos
Z √© o resultado da somat√≥ria
z=f(x1,x2)
f(x1,x2)=(x1 ‚ãÖw1)+(x2 ‚ãÖw2)
```

> **NOTE:**  
> Vejam que n√≥s dividimos nosso PDF em v√°rios `chunks (documentos)` e `overlap (100 palavras cada)`.

Agora n√≥s vamos utilizar uma Rede Neural que foi treinada para pegar textos (palavras) e transformar em Embeddings (vetores):

```bash
pip install -U sentence-transformers
```

```bash
pip install -U langchain-huggingface
```

[rag_retriever.py](rag_retriever.py)
```python
from langchain_huggingface import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
```

> Continuando, voc√™s concordam que n√≥s temos que salvar nossos `chunks` em algum banco de dados?

Uma abordagem comum no mundo de IA hoje em dia √© utilizar a biblioteca **[FAISS (Facebook AI Similarity Search)](https://github.com/facebookresearch/faiss)** que √© um tipo de arquivo espec√≠fico para armazenar dados vetoriais:

[rag_retriever.py](rag_retriever.py)
```python
from langchain_community.vectorstores import FAISS

db_path = "faiss_database"  # Database path

if os.path.exists(db_path):
    vectordb = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
    vectordb.add_documents(chunks)
else:
    vectordb = FAISS.from_documents(chunks, embeddings)

vectordb.save_local(db_path)
```

Se voc√™ prestar aten√ß√£o vai ver que foi criado um diret√≥rio chamado `faiss_database` onde os `chunks` estar√£o armazenados. Por√©m, esses dados est√£o em bin√°rio.

> **Como eu vejo eles agora?**

Bem, eu tenho script simples, s√≥ para isso:

<details>

<summary>FAISS to JSON</summary>

<br/>

[faiss.view.py](faiss_database/faiss.view.py)
```python
import os
import json
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

# Caminho para o banco de dados FAISS
db_path = "faiss_database"

# Instancia os embeddings Hugging Face (gratuito)
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# Carrega o √≠ndice FAISS
db = FAISS.load_local(
    db_path,
    embeddings,
    allow_dangerous_deserialization=True
)

# Acessa o √≠ndice e os documentos
faiss_index = db.index
documentos = list(db.docstore._dict.values())

# Constr√≥i os dados
dados = []
for i, doc in enumerate(documentos):
    vetor = faiss_index.reconstruct(i)
    item = {
        "id": i,
        "conteudo": doc.page_content.replace("\n", " ").strip(),
        "vetor_parcial": vetor[:10].tolist()
    }
    dados.append(item)

# Define o caminho completo para salvar o JSON no mesmo diret√≥rio do √≠ndice
json_path = os.path.join(db_path, "faiss_exportado.json")

# Salva o arquivo JSON
with open(json_path, "w", encoding="utf-8") as jsonfile:
    json.dump(dados, jsonfile, ensure_ascii=False, indent=2)

print(f"Arquivo criado com sucesso.")
```

</details>

Agora se voc√™ olhar em [faiss_exportado.json](faiss_database/faiss_exportado.json) vai ver um JSON com os `chunks` armazenados no formato JSON com os seus respectivos vetores.







































































































<!--- ( Implementa√ß√£o ) --->

---

<div id="django-core"></div>

## Criando o projeto "core" do djando

De in√≠cio vamos come√ßar criando nosso projeto django `core` na `raiz (.)` do nosso projeto:

```bash
django-admin startproject core .
```

> **NOTE:**  
> Para rodar o nosso servidor basta digitar `python manage.py runserver` na raiz do projeto. 




















---

<div id="app-users"></div>

## Criando e configurando o app "users"

> √â comum em problemas da *Ci√™ncias da Computa√ß√£o* n√≥s dividimos um problema grande em pequenas partes, esse conceito √© conhecido como `Dividir para Conquistar`. Por exemplo, para criar um sistema grande como o *Instagram* √© interessante n√≥s dividirmmos esse problemas em pequenas partes - No django n√≥s utilizamos o conceito de *"apps"* para dividir nosso problema em partes menores.

Com isso, aqui n√≥s vamos trabalhar na autentica√ß√£o dos usu√°rios e para isso vamos criar o app `users`:

```bash
python manage.py startapp users
```

Por√©m, para o django reconhecer esse app, precisamos adicionar ele ao `settings.py` do nosso projeto `core`:

[settings.py](core/settings.py)
```python
INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    'users',
]
```

Agora n√≥s precisamos criar uma `rota/url` para o nosso app `users`. Para isso n√≥s linkamos o arquivo `users/urls.py` do nosso app `users` ao `core/urls.py` do nosso projeto `core`:

[core/urls.py](core/urls.py)
```python
from django.contrib import admin
from django.urls import path, include

urlpatterns = [
    path('admin/', admin.site.urls),
    path('users/', include('users.urls')),
]
```

> **NOTE:**  
> De in√≠cio o nosso app n√£o vai ter o arquivo `urls.py` pois ele ainda vai ser criado.




















---

<div id="mapping-users-to-register-view"></div>

## Mapeando a rota "users" com a view "register"

Agora n√≥s vamos mapear para quando o usu√°rio clicar na rota/url `users/` ele vai ser redirecionado para a view `register` do nosso app `users`:

[users/urls.py](users/urls.py)
```python
from django.urls import path
from .views import register

urlpatterns = [
    path('register/', register, name='register'),
]
```

Agora n√≥s precisamos criar o m√©todo `register` na view `users/views.py`:

[users/views.py](users/views.py)
```python
from django.shortcuts import render
from django.http import HttpResponse


def register(request):
    return HttpResponse("Hello World!")
```

Agora se voc√™ for em [http://127.0.0.1:8000/users/register/](http://127.0.0.1:8000/users/register/) voc√™ ver√° a seguinte mensagem **"Hello World!"**.

















































































<!--- ( üöÄ Instala√ß√£o / Execu√ß√£o local ) --->

---

<div id="settings"></div>

## üöÄ Instala√ß√£o / Execu√ß√£o local

### Crie e ative o ambiente virtual (recomendado)

```bash
python -m venv environment
```

*LINUX:*  
```bash
source environment/bin/activate
```

*WINDOWS:*  
```bash
source environment/Scripts/activate
```

### Atualize o pip

```bash
python -m pip install --upgrade pip
```

### Instale as depend√™ncias

```bash
pip install -U -v --require-virtualenv -r requirements.txt
```





---

**Rodrigo** **L**eite da **S**ilva - **rodrigols89**
